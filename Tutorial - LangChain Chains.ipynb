{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2a2bb2-5c59-497c-b83e-35e37c165ad0",
   "metadata": {},
   "source": [
    "# Tutorial - LangChain Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bff76d-3219-4276-b19f-65416628cd13",
   "metadata": {},
   "source": [
    "### Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e08df58d-0c8f-445b-afb0-8cbd8f5e2adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2326706397.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install IPython -q\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain\n",
    "#!pip install python-dotenv\n",
    "pip install IPython -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0f470-4f00-46f4-8537-2aea8915e2bc",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07227d0-5c21-49d4-81fb-aa7a2c08385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_openai():\n",
    "    import os\n",
    "    from openai import OpenAI\n",
    "    from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "    load_dotenv(find_dotenv(), override=True)\n",
    "    api_key = os.environ.get('OPENAI_API_KEY')\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    print(\"API Key Loaded:\", api_key is not None)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babae56c-44f3-49fd-a0fd-ab4913fd5545",
   "metadata": {},
   "source": [
    "### Create OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c369d937-ff48-4c2f-a6e1-820f6d2170a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Loaded: True\n"
     ]
    }
   ],
   "source": [
    "client = setup_openai()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2dc8f-b0ae-419f-9e9f-1e5b366c2847",
   "metadata": {},
   "source": [
    "### Simple Chain Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12feae97-4bb3-402b-a361-86d34a50d3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an experienced Data Scientist with over 20 years of experience.\n",
      "Write a few sentences about the following topic \"Automatic Speech Recognition\" in English.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "template=\"\"\"\n",
    "You are an experienced Data Scientist with over 20 years of experience.\n",
    "Write a few sentences about the following topic \"{topic}\" in {language}.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "input_variables = {'topic':'Automatic Speech Recognition','language':'English'}\n",
    "\n",
    "output = chain.invoke(input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4825b30b-d01e-4343-b9fa-c50f1596b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'Automatic Speech Recognition', 'language': 'English', 'text': 'Automatic Speech Recognition (ASR) is a technology that allows computers to transcribe spoken language into text. It utilizes advanced algorithms and machine learning techniques to accurately interpret and convert speech to text in real-time. ASR has a wide range of applications, from voice-controlled virtual assistants like Siri and Alexa to automated transcription services for meetings and interviews. As technology continues to advance, ASR systems are becoming increasingly accurate and reliable, revolutionizing the way we interact with and use spoken language in various industries.'}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "964b5309-348d-4d71-89ff-5514a079eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your country:  United Kingdom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of United Kingdom. List the top 3 places to visit in that country. Use bullet points\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'country': 'United Kingdom', 'text': 'The capital of the United Kingdom is London.\\n\\nTop 3 places to visit in the United Kingdom:\\n- Buckingham Palace\\n- The British Museum\\n- The Tower of London'}\n"
     ]
    }
   ],
   "source": [
    "template = 'What is the capital of {country}. List the top 3 places to visit in that country. Use bullet points'\n",
    "prompt_tempate=PromptTemplate.from_template(template=template)\n",
    "chain=LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_tempate,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "country=input('Enter your country: ')\n",
    "output=chain.invoke(country)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8011e716-74d4-4cbb-a55f-bab9e5198114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United Kingdom is London.\n",
      "\n",
      "Top 3 places to visit in the United Kingdom:\n",
      "- Buckingham Palace\n",
      "- The British Museum\n",
      "- The Tower of London\n"
     ]
    }
   ],
   "source": [
    "print(output['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8ada8-4741-4cda-9b71-fbbe0664ac24",
   "metadata": {},
   "source": [
    "### Sequential Chain Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "269e5f39-3211-4b18-890a-e6fdcab0fab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure, here is an example of a function that implements binary classification using Python:\n",
      "\n",
      "```python\n",
      "def binary_classification(data, threshold):\n",
      "    predictions = []\n",
      "    for value in data:\n",
      "        if value >= threshold:\n",
      "            predictions.append(1)\n",
      "        else:\n",
      "            predictions.append(0)\n",
      "    return predictions\n",
      "\n",
      "# Example usage\n",
      "data = [0.1, 0.5, 0.8, 0.3, 0.6]\n",
      "threshold = 0.5\n",
      "predictions = binary_classification(data, threshold)\n",
      "print(predictions)\n",
      "```\n",
      "\n",
      "In this function, we take a list of data points and a threshold value as input. For each data point, if the value is greater than or equal to the threshold, we predict a class label of 1, otherwise we predict a class label of 0. The function returns a list of these predictions.\n",
      "\n",
      "This is a simple example of binary classification, where we are dividing the data into two classes based on a threshold value. In practice, more advanced machine learning algorithms like logistic regression, support vector machines, or neural networks are often used for binary classification tasks.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe provided Python function, `binary_classification`, performs a simple form of binary classification on a list of numerical data points based on a given threshold. Binary classification is a common task in machine learning and statistics where each input is classified into one of two categories, often referred to as classes or labels. In this specific implementation, the function takes two parameters:\n",
      "\n",
      "1. `data`: a list of numerical data points. These data points are the subjects of the classification, where each element in the list represents a singular observation or value that needs to be classified into one of two categories.\n",
      "   \n",
      "2. `threshold`: a numerical value serving as the boundary or cutoff point for classification. This threshold dictates which class each data point belongs to based on its value relative to the threshold.\n",
      "\n",
      "The function operates as follows:\n",
      "\n",
      "- It initializes an empty list named `predictions` to store the classification results or predictions for each data point.\n",
      "  \n",
      "- Then, it iterates over each data point in the `data` list. For every iteration (i.e., for every data point), the function compares the data point to the `threshold` value.\n",
      "  \n",
      "  - If a data point's value is greater than or equal to the `threshold`, the function concludes that this particular data point belongs to the class represented by `1`. It then appends `1` to the `predictions` list, signifying that the data point is classified into the first category.\n",
      "    \n",
      "  - Conversely, if a data point's value is less than the `threshold`, the function deduces that this data point belongs to the class represented by `0`. It then appends `0` to the `predictions` list, indicating that the data point is classified into the second category.\n",
      "\n",
      "- After all the data points have been processed, the function returns the `predictions` list, which now contains a sequence of `0`s and `1`s. Each element in the `predictions` list corresponds to the classification result of the respective data point in the input `data` list, based on the specified `threshold`.\n",
      "\n",
      "The given example usage shows how to apply the `binary_classification` function to a list of data points, `[0.1, 0.5, 0.8, 0.3, 0.6]`, with a threshold set to `0.5`. Applying the function with these inputs results in the list `[0, 0, 1, 0, 1]`. This output indicates that the third and fifth data points in the input list are classified into category `1` (since their values are greater than or equal to the threshold), while the rest are classified into category `0`.\n",
      "\n",
      "This standalone function, while simplistic, exemplifies the core concept of binary classification—leveraging a single numeric condition to segregate data points into two distinct groups. Nonetheless, for most real-world applications, particularly those involving complicated patterns or requiring high accuracy, more sophisticated techniques (e.g., logistic regression, support vector machines, neural networks) are preferred. These advanced methods can handle multidimensional input data and nonlinear decision boundaries, thereby providing more flexible and powerful solutions for binary classification challenges.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The provided Python function, `binary_classification`, performs a simple form of binary classification on a list of numerical data points based on a given threshold. Binary classification is a common task in machine learning and statistics where each input is classified into one of two categories, often referred to as classes or labels. In this specific implementation, the function takes two parameters:\n",
      "\n",
      "1. `data`: a list of numerical data points. These data points are the subjects of the classification, where each element in the list represents a singular observation or value that needs to be classified into one of two categories.\n",
      "   \n",
      "2. `threshold`: a numerical value serving as the boundary or cutoff point for classification. This threshold dictates which class each data point belongs to based on its value relative to the threshold.\n",
      "\n",
      "The function operates as follows:\n",
      "\n",
      "- It initializes an empty list named `predictions` to store the classification results or predictions for each data point.\n",
      "  \n",
      "- Then, it iterates over each data point in the `data` list. For every iteration (i.e., for every data point), the function compares the data point to the `threshold` value.\n",
      "  \n",
      "  - If a data point's value is greater than or equal to the `threshold`, the function concludes that this particular data point belongs to the class represented by `1`. It then appends `1` to the `predictions` list, signifying that the data point is classified into the first category.\n",
      "    \n",
      "  - Conversely, if a data point's value is less than the `threshold`, the function deduces that this data point belongs to the class represented by `0`. It then appends `0` to the `predictions` list, indicating that the data point is classified into the second category.\n",
      "\n",
      "- After all the data points have been processed, the function returns the `predictions` list, which now contains a sequence of `0`s and `1`s. Each element in the `predictions` list corresponds to the classification result of the respective data point in the input `data` list, based on the specified `threshold`.\n",
      "\n",
      "The given example usage shows how to apply the `binary_classification` function to a list of data points, `[0.1, 0.5, 0.8, 0.3, 0.6]`, with a threshold set to `0.5`. Applying the function with these inputs results in the list `[0, 0, 1, 0, 1]`. This output indicates that the third and fifth data points in the input list are classified into category `1` (since their values are greater than or equal to the threshold), while the rest are classified into category `0`.\n",
      "\n",
      "This standalone function, while simplistic, exemplifies the core concept of binary classification—leveraging a single numeric condition to segregate data points into two distinct groups. Nonetheless, for most real-world applications, particularly those involving complicated patterns or requiring high accuracy, more sophisticated techniques (e.g., logistic regression, support vector machines, neural networks) are preferred. These advanced methods can handle multidimensional input data and nonlinear decision boundaries, thereby providing more flexible and powerful solutions for binary classification challenges.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# First Chain\n",
    "llm1 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template='''\n",
    "    You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}.\n",
    "    '''\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "# Second Chain\n",
    "llm2 = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=1.2)\n",
    "\n",
    "prompt_template2=PromptTemplate.from_template(\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n",
    "\n",
    "# Create the sequential chain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1,chain2],verbose=True)\n",
    "output=overall_chain.invoke('Binary Classification')\n",
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f8022-5c2f-4e0c-87ab-139e63cc4aec",
   "metadata": {},
   "source": [
    "### 3-Step AI Storyteller: Prompt Generation, Evaluation, and Setting Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f1d8a02-ab3e-46b4-a72e-24282fa3a773",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 41\u001b[0m\n\u001b[1;32m     31\u001b[0m evaluate_prompt_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mEvaluate the following writing prompt on a scale of 1 to 5 \u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m(1 being not creative and 5 being highly creative):\u001b[39m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mPrompt: \u001b[39m\u001b[38;5;132;01m{prompt}\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124mScore:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m  \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Create an LLMChain to evaluate the prompt\u001b[39;00m\n\u001b[1;32m     39\u001b[0m evaluate_prompt_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m     40\u001b[0m     llm\u001b[38;5;241m=\u001b[39mChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m),  \u001b[38;5;66;03m# Lower temperature for more objective evaluation\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mevaluate_prompt,\n\u001b[1;32m     42\u001b[0m     output_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Name the output of this chain as \"score\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# ------------------ Chain 3: Suggest a Setting ------------------\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Create a PromptTemplate to suggest a setting based on the generated prompt\u001b[39;00m\n\u001b[1;32m     48\u001b[0m suggest_setting_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mSuggest an interesting setting for the following writing prompt:\u001b[39m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;124mPrompt: \u001b[39m\u001b[38;5;132;01m{prompt}\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;124mSetting:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from langchain.chains import SequentialChain, LLMChain \n",
    "# Import classes for creating chains of LLMs and executing them sequentially\n",
    "from langchain_openai import ChatOpenAI \n",
    "# Import the ChatOpenAI class, which provides a wrapper for interacting with the OpenAI's chat models (like GPT-3.5 and GPT-4)\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate \n",
    "# Import classes for defining the structure of prompts sent to the language models.\n",
    "from IPython.display import HTML \n",
    "# Import the HTML class to display the results in a nicely formatted way within a Jupyter notebook\n",
    "\n",
    "# Initialize the language model (You can experiment with different models)\n",
    "llm = ChatOpenAI(temperature=1.0)  # Higher temperature for more creative output\n",
    "\n",
    "# ------------------ Chain 1: Generate a Writing Prompt ------------------\n",
    "\n",
    "# Create a ChatPromptTemplate to structure the prompt as a conversation\n",
    "generate_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Generate a creative writing prompt that includes a genre, a character, and a conflict.\")  # Instruction for the language model\n",
    "])\n",
    "\n",
    "# Create an LLMChain that uses the ChatOpenAI model and the prompt template\n",
    "generate_prompt_chain = LLMChain(\n",
    "    llm=llm,  \n",
    "    prompt=generate_prompt_template,\n",
    "    output_key=\"prompt\"  # Name the output of this chain as \"prompt\" \n",
    ")\n",
    "\n",
    "# ------------------ Chain 2: Evaluate the Prompt ------------------\n",
    "\n",
    "# Create a PromptTemplate to evaluate the creativity of the generated prompt\n",
    "evaluate_prompt_template = \"\"\"Evaluate the following writing prompt on a scale of 1 to 5 \n",
    "(1 being not creative and 5 being highly creative):\n",
    "\n",
    "Prompt: {prompt}\n",
    "\n",
    "Score:\"\"\"  \n",
    "\n",
    "# Create an LLMChain to evaluate the prompt\n",
    "evaluate_prompt_chain = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0.0),  # Lower temperature for more objective evaluation\n",
    "    prompt=evaluate_prompt,\n",
    "    output_key=\"score\"  # Name the output of this chain as \"score\"\n",
    ")\n",
    "\n",
    "# ------------------ Chain 3: Suggest a Setting ------------------\n",
    "\n",
    "# Create a PromptTemplate to suggest a setting based on the generated prompt\n",
    "suggest_setting_template = \"\"\"Suggest an interesting setting for the following writing prompt:\n",
    "\n",
    "Prompt: {prompt}\n",
    "\n",
    "Setting:\"\"\"\n",
    "\n",
    "suggest_setting_prompt = PromptTemplate(input_variables=[\"prompt\"], template=suggest_setting_template)\n",
    "\n",
    "# Create an LLMChain to suggest a setting\n",
    "suggest_setting_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=suggest_setting_prompt,\n",
    "    output_key=\"setting\"  # Name the output of this chain as \"setting\"\n",
    ")\n",
    "\n",
    "# ------------------ Combine Chains into a SequentialChain ------------------\n",
    "\n",
    "# Combine all three chains into a single sequential chain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[generate_prompt_chain, evaluate_prompt_chain, suggest_setting_chain],\n",
    "    input_variables=[],   # This chain doesn't require any initial input\n",
    "    output_variables=[\"prompt\", \"score\", \"setting\"],  # Define the output keys we want\n",
    "    verbose=True  # Optional: Show the chain's thought process for debugging\n",
    ")\n",
    "\n",
    "# ------------------ Run the Chain ------------------\n",
    "# Execute the chain with an empty dictionary as input\n",
    "result = overall_chain.invoke({})  \n",
    "print(\"Generated Prompt:\", result['prompt'])\n",
    "print(\"Creativity Score:\", result['score'])\n",
    "print(\"Suggested Setting:\", result['setting'])\n",
    "\n",
    "\n",
    "# ------------------ Format and Display the Output ------------------\n",
    "# Create an HTML string to format the results\n",
    "html_output = f\"\"\"\n",
    "<div style=\"border: 1px solid #ccc; padding: 20px; border-radius: 5px;\">\n",
    "  <h2>AI-Generated Writing Prompt</h2>\n",
    "  <p>{result['prompt']}</p>\n",
    "  <h3>Creativity Score</h3>\n",
    "  <p>{result['score']}/5</p>\n",
    "  <h3>Suggested Setting</h3>\n",
    "  <p>{result['setting']}</p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the formatted HTML in the Jupyter Notebook\n",
    "HTML(html_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dde77a-6a6e-4d2a-a254-492215e0163a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3216f-87f3-466d-add3-f3d5b8bcfb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede217e2-814a-4a2a-a60b-1965b1853525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71878c5a-fc9e-47c7-b0c1-8e629a20b01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8f082-2c6c-478b-8012-528dbb788fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62260fab-3e22-48fe-96be-6548567586ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d18d5-42fc-4e5c-a493-b1146e4d5c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d799f-b80d-4df8-8265-e5e9821591ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f032c-6a52-4999-954e-e8c062625bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f77cfb-01ea-4efa-ae78-da27c5511fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0ee06-4247-4ca4-bd18-d2c7fbc76de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1fe216-be37-4483-8479-2c2c51bd61f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01144de9-fa63-4232-ace4-e4bce4a553cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e333df5-9fbd-4ec9-9079-523dd872818c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d072b2-8293-4afc-9978-ebce5351fd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8013ce3e-54e6-44ac-8f52-e0a038924558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c7c18-28a5-46f2-b294-679265b5b79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9ea0c-e6bf-47da-8053-bd3cd62d62e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f08441-6658-4798-9af9-7e423c3494d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410737db-8ba3-4999-8c2a-a4e4976eedbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ff0c6-a10b-4b9e-a695-93d0c974bbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ea4ac-5d55-4935-8eba-ba406205cc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af44c71-b4c3-4cde-a84a-5f120d43b787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed8bb8-0458-4810-83d8-69e025b01797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
